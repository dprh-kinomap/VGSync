Tip: für mini-chart:
# falls du ggf. 40 Punkte statt 30 willst:
# self.mini_chart_widget.set_max_points(40)



Performance:

    Bei sehr großen GPX-Dateien könnte die ständige In‐Place-Recalc-Funktion (recalc_gpx_data) bei jedem kleinen Änderungsschritt spürbar werden. Evtl. Caching-Strategien oder Teil-Recalc.
    Für Videos >1–2 Stunden oder sehr viele Segmente könnte das Cut-Handling (Liste in _cut_intervals) unübersichtlich werden. Möglicherweise Sortierung + Merge-Logik (teilweise vorhanden) könnte man an einer Stelle bündeln.



Tatsächlich nutzen professionelle Video-Editoren wie Shotcut, DaVinci Resolve, Premiere & Co. im Hintergrund weit mehr als eine simple „set_time(...)+Pause“‐Logik. Oft arbeiten sie mit komplexen Media‐Frameworks (z. B. MLT, FFmpeg, oder proprietäre Engines), die Folgendes erlauben:

    Frame-genaues Decoding im Speicher
    Anstatt nur dem Player zu sagen „springe zu Sekunde X und zeig das an“, haben diese Libraries direkten Zugriff auf den Videostream. Sie können quasi einen beliebigen Frame anfordern und dekodieren, ohne kurz abspielen zu müssen.

    Caching / Prefetching
    Video‐Editoren legen häufig bereits im Hintergrund dekodierte Frames (oder Keyframes plus Delta‐Pakete) in einem Cache ab, sodass der Bildwechsel beim Scrollen oder Step‐Forward/Step‐Backward nahezu sofort erfolgt.

    Schnelle GPU‐Decoding‐Pipelines
    Viele Editor‐Programme lassen die GPU via NVDEC, QuickSync, DXVA, etc. direkt Frames dekodieren und halten einen Puffer bereit. Dann können sie blitzschnell auf ein bestimmtes Frame zugreifen, ohne erst “real“ abspielen zu müssen.

    Eigene Playback‐Engine statt eines Standard‐Players
    Während wir in Python & VLC meistens an dessen Mediaplayer‐Komponente gebunden sind, haben professionelle Programme eigene Player/Render‐Pipelines. Die „Timeline“ oder „Scrubber“ ruft dort direkt einen „FrameReader“ auf, der FFmpeg/MLT etc. steuert und einen beliebigen Frame decodiert und rendert.

Warum ist das bei dir anders?

    VLCs MediaPlayer ist als Abspielkomponente konzipiert.
    Wenn du set_time(t) aufrufst, wird intern erst beim nächsten „Play Cycle“ das Decoding angestoßen.
    VLC selbst kann durchaus framegenau decodieren (z. B. mit LibVLC in einem komplexeren Setup), aber die einfache MediaPlayer‐API betreibt in der Regel „Zeitsprung + Abspielen“.

Kurz: Die professionellen Editoren haben eine feingranulare Kontrolle über den Decoding‐Prozess. Wir dagegen nutzen eher den „fertigen“ Player‐Ansatz von VLC, der eben ein kurzes Play braucht, um das neue Frame anzuzeigen.
Kann man das auch selbst framegenau umsetzen?

Ja, wenn man z. B. FFmpeg (bzw. PyAV, ffmpeg-python oder MLT in Python) direkt nutzt, könnte man eine Art „FrameReader“ bauen:

    Du initialisierst den Decoder mit dem Videofile.
    Bei jedem Step sagst du: „Gib mir das Frame an Index N“ oder „Gib mir das Frame zum Timestamp T“.
    Du bekommst dann das raw‐Video‐Image, das du selbst in ein Qt‐Label oder in eine OpenGL‐Textur malst.

So hat man volle Kontrolle – ohne Playback. Aber das ist eben eine ganz andere, viel komplexere Implementierung als „einfach LibVLC im Abspielmodus benutzen“.